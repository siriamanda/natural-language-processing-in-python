{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "496a855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3982322",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sraaf/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/sraaf/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sraaf/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download(\"wordnet\")\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01f9df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "\n",
    "df = pd.read_csv('available_csv_file')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f75b658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 2 variables of the columns in the dataframe\n",
    "\n",
    "inputs = df['text']\n",
    "labels = df['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51f2079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for imbalanced classes. Over or under-represented classes can be an issue when checking the models performance\n",
    "\n",
    "labels.hist(figsize = (10, 5));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c9f02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split \n",
    "\n",
    "inputs_train, inputs_test, Ytrain, Ytest = train_test_split(inputs, labels, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe7df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instintiate countvector object\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b44737",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = vectorizer.fit_transform(inputs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4289ed4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtest = vectorizer.transform(inputs_test)     # We do not fit test data as it is meant to \n",
    "                                              # represent the data we want to apply the model to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b1818f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what percentage of values are non-zero?\n",
    "\n",
    "(Xtrain != 0).sum() / np.prod(Xtrain.shape)      # number of non-zero values divided by the shape of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be3d0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))     # returns the accuracy\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef2247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Including param stopwords\n",
    "\n",
    "vectorizer = CountVectorizer(stop_words = 'english')\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)  \n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f330c68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for mapping POS tags in nltk\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return word_net.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce8b3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create class for tokenizing and lemmatizing\n",
    "\n",
    "class LemmaTokenizer:     # create an object\n",
    "    def __init__(self):       \n",
    "        self.wnl = WordNetLemmatizer()             # instantiate a word net lemmatizer object\n",
    "    def __call__(self, doc):                       # define the call function that takes the document as argument\n",
    "        tokens = word_tokenize(doc)\n",
    "        words_and_tags = nltk.pos_tags(tokens)     # Convert document into tokens\n",
    "        return [self.wnl.lemmatize(word, pos = get_wordnet_pos(tag)) \\\n",
    "               for word, tag in words_and_tags]    # obtain parts of speech tags and return list of tuples containing each word and corresponding tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589bf9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with created object\n",
    "vectorizer = CountVectorizer(tokenizer = LemmaTokenizer)\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)  \n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a11492",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemTokenizer:     # create an object\n",
    "    def __init__(self):       \n",
    "        self.porter = PorterStemmer()             # instantiate a word net lemmatizer object\n",
    "    def __call__(self, doc):                      # define the call function that takes the document as argument\n",
    "        tokens = word_tokenize(doc)               \n",
    "        return [self.porter.stem(t) for t in tokens]    # returns list of stemmed tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881dffc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with created object\n",
    "vectorizer = CountVectorizer(tokenizer = StemTokenizer)\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)  \n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc915a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_tokenizer(s):\n",
    "    return s.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9398c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run model with created object\n",
    "vectorizer = CountVectorizer(tokenizer = simple_tokenizer)\n",
    "Xtrain = vectorizer.fit_transform(inputs_train)\n",
    "Xtest = vectorizer.transform(inputs_test)  \n",
    "model = MultinomialNB()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"train score:\", model.score(Xtrain, Ytrain))\n",
    "print(\"test score:\", model.score(Xtest, Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9fcd87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f8d10d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
